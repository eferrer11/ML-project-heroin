{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:09:20.152085Z",
     "iopub.status.busy": "2024-12-18T16:09:20.150910Z",
     "iopub.status.idle": "2024-12-18T16:09:20.159233Z",
     "shell.execute_reply": "2024-12-18T16:09:20.157822Z",
     "shell.execute_reply.started": "2024-12-18T16:09:20.152034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:09:23.035897Z",
     "iopub.status.busy": "2024-12-18T16:09:23.035408Z",
     "iopub.status.idle": "2024-12-18T16:09:23.105241Z",
     "shell.execute_reply": "2024-12-18T16:09:23.104091Z",
     "shell.execute_reply.started": "2024-12-18T16:09:23.035854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "X_train = data_train.iloc[:, 6:]\n",
    "X_test = data_test.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:09:26.285133Z",
     "iopub.status.busy": "2024-12-18T16:09:26.284698Z",
     "iopub.status.idle": "2024-12-18T16:09:26.740096Z",
     "shell.execute_reply": "2024-12-18T16:09:26.738862Z",
     "shell.execute_reply.started": "2024-12-18T16:09:26.285094Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = data_train[\"PURITY\"]/100\n",
    "seed = 43\n",
    "\"\"\"\n",
    "# Combine original data with PCA components\n",
    "standardizer = StandardScaler()\n",
    "X_st = standardizer.fit_transform(X_train)\n",
    "\"\"\"\n",
    "# Perform PCA to retain 95% of the variance\n",
    "pca = PCA(42)\n",
    "pca.fit(X_train)\n",
    "X_pca = pca.transform(X_train)\n",
    "\n",
    "X_normalised = preprocessing.normalize(X_pca)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_normalised, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).clone().detach()\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1).clone().detach()\n",
    "X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32).clone().detach()\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).reshape(-1, 1).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:09:31.429856Z",
     "iopub.status.busy": "2024-12-18T16:09:31.429240Z",
     "iopub.status.idle": "2024-12-18T16:09:31.447658Z",
     "shell.execute_reply": "2024-12-18T16:09:31.444833Z",
     "shell.execute_reply.started": "2024-12-18T16:09:31.429794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_test)\n",
    "X_test_normalised = preprocessing.normalize(X_pca)\n",
    "X_test_tensor = torch.tensor(X_test_normalised, dtype=torch.float32).clone().detach() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:08:02.367899Z",
     "iopub.status.busy": "2024-12-18T16:08:02.367494Z",
     "iopub.status.idle": "2024-12-18T16:08:02.793928Z",
     "shell.execute_reply": "2024-12-18T16:08:02.792089Z",
     "shell.execute_reply.started": "2024-12-18T16:08:02.367861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = data_train[\"PURITY\"] / 100\n",
    "\n",
    "# Diviser les données en train et validation\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardisation des données (avant PCA)\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "X_valid_standardized = scaler.transform(X_valid)\n",
    "X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "# PCA sur les données standardisées\n",
    "pca = PCA(n_components=42)  # 95% variance expliquée\n",
    "X_train_pca = pca.fit_transform(X_train_standardized)\n",
    "X_valid_pca = pca.transform(X_valid_standardized)\n",
    "X_test_pca = pca.transform(X_test_standardized)\n",
    "\n",
    "# Convertir en tensors PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_valid_tensor = torch.tensor(X_valid_pca, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:12:26.918396Z",
     "iopub.status.busy": "2024-12-18T17:12:26.917904Z",
     "iopub.status.idle": "2024-12-18T17:12:26.939464Z",
     "shell.execute_reply": "2024-12-18T17:12:26.938046Z",
     "shell.execute_reply.started": "2024-12-18T17:12:26.918354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Définir le modèle de réseau de neurones simple\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, lin_layer_sizes,\n",
    "\n",
    "                 outpout_size, lin_layer_dropouts, activation):\n",
    "        super().__init__()       \n",
    "        if activation == 0:\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == 1:\n",
    "            self.activation = nn.SiLU()\n",
    "        elif activation == 2:\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation == 3:\n",
    "            self.activation = nn.LeakyReLU()  \n",
    "\n",
    "        # Linear Layers\n",
    "        first_lin_layer = nn.Linear(input_size, lin_layer_sizes[0])\n",
    "        self.lin_layers = nn.ModuleList([first_lin_layer] + [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1]) for i in range(len(lin_layer_sizes) - 1)])     \n",
    "\n",
    "        # Output Layer\n",
    "        self.outpout_layer = nn.Linear(lin_layer_sizes[-1], outpout_size)\n",
    "        \n",
    "        # Dropout Layers\n",
    "        self.dropout_layers = nn.ModuleList([nn.Dropout(rate) for rate,size in zip(lin_layer_dropouts,lin_layer_sizes)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for lin_layer, dropout_layer in zip(self.lin_layers, self.dropout_layers):\n",
    "            x = lin_layer(x)     \n",
    "            x = self.activation(x)\n",
    "            x = dropout_layer(x)\n",
    " \n",
    "        x = self.outpout_layer(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "  \n",
    "        return x\n",
    "\n",
    "# Définir la classe NeuralNetRegressor\n",
    "class NeuralNetRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, input_size, random_state, eta=0.001, max_epochs=100, batch=10, lin_layer_sizes = [50, 50],\n",
    "            outpout_size = 1, lin_layer_dropouts = [0.4, 0.4], activation = 0):\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.random_state = random_state\n",
    "        self.eta = eta\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch = batch\n",
    "        self.lin_layer_sizes = lin_layer_sizes\n",
    "        self.outpout_size = outpout_size\n",
    "        self.lin_layer_dropouts = lin_layer_dropouts\n",
    "        self.activation = activation\n",
    "        self.model = FeedForwardNN(input_size, lin_layer_sizes,\n",
    "                 outpout_size, lin_layer_dropouts, activation)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def fit(self, X, y, do_print=False):\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.eta)\n",
    "        X_tensor = torch.tensor(X).clone().detach().float()\n",
    "        y_tensor = torch.tensor(y).clone().detach().float()\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch, shuffle=True)\n",
    "        self.model.train()\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(self.max_epochs):\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "                outputs = self.model(batch_X)  # Forward pass\n",
    "                loss = self.criterion(outputs, batch_y)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update parameters\n",
    "                epoch_loss += loss.item()\n",
    "            if do_print:\n",
    "\n",
    "                print(f\"Epoch {epoch+1}/{self.max_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "        return self  \n",
    "\n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor).flatten()\n",
    "        return outputs.numpy()\n",
    "        \n",
    "    def parameters(self):\n",
    "        return self.model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:11:58.519266Z",
     "iopub.status.busy": "2024-12-18T16:11:58.518750Z",
     "iopub.status.idle": "2024-12-18T16:11:58.526839Z",
     "shell.execute_reply": "2024-12-18T16:11:58.525704Z",
     "shell.execute_reply.started": "2024-12-18T16:11:58.519225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomLayers:\n",
    "    def __init__(self,min_layers, max_layers, min_nodes, max_nodes):\n",
    "        self.min_nodes = min_nodes\n",
    "        self.max_nodes = max_nodes\n",
    "        self.min_layers = min_layers\n",
    "        self.max_layers = max_layers\n",
    "\n",
    "    def rvs(self, random_state=None):\n",
    "        if random_state is not None:\n",
    "            prev = randint.random_state\n",
    "            randint.random_state = random_state \n",
    "\n",
    "        res = [randint.rvs(self.min_nodes, self.max_nodes) for _ in range(randint.rvs(self.min_layers, self.max_layers))]\n",
    "\n",
    "        if random_state is not None:\n",
    "            randint.random_state = prev\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T16:12:01.049358Z",
     "iopub.status.busy": "2024-12-18T16:12:01.048945Z",
     "iopub.status.idle": "2024-12-18T16:12:01.056862Z",
     "shell.execute_reply": "2024-12-18T16:12:01.055552Z",
     "shell.execute_reply.started": "2024-12-18T16:12:01.049313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RandomDropout:\n",
    "    def __init__(self, max_layers,min_dropout,max_dropout):\n",
    "        self.min_dropout = min_dropout\n",
    "        self.max_dropout = max_dropout\n",
    "        self.max_layers = max_layers\n",
    "\n",
    "    def rvs(self, random_state=None):\n",
    "        if random_state is not None:\n",
    "            prev = uniform.random_state\n",
    "            uniform.random_state = random_state \n",
    "        res = [uniform.rvs(self.min_dropout, self.max_dropout) for _ in range(self.max_layers)]\n",
    "\n",
    "        if random_state is not None:\n",
    "            uniform.random_state = prev\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:12:50.791927Z",
     "iopub.status.busy": "2024-12-18T17:12:50.791447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(net, params_dist, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle avec GridSearch\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m random_grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m nouveau_model \u001b[38;5;241m=\u001b[39m random_grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MSE: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (random_grid_result\u001b[38;5;241m.\u001b[39mbest_score_, random_grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[1;34m(self, X, y, do_print)\u001b[0m\n\u001b[0;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[0;32m     74\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_X)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     76\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     77\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elvua\\miniconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\functional.py:3792\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialiser le modèle\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "input_size = X_train_tensor.shape[1]\n",
    "net = NeuralNetRegressor(input_size=input_size, random_state=seed)\n",
    "\n",
    "max_layers = 5\n",
    "\n",
    "# Définir les paramètres pour GridSearch\n",
    "params_dist = {\n",
    "\n",
    "    'eta': loguniform(1e-4, 1e-1),\n",
    "    'max_epochs': randint(200, 500),\n",
    "    'batch': randint(8, 32),\n",
    "    'lin_layer_sizes': RandomLayers(1,max_layers,32,128),  # Taille de 1 à 4 couches, entre 32 et 128 neurones par couche\n",
    "    'lin_layer_dropouts': RandomDropout(max_layers,0.,1.),\n",
    "    'activation': randint(0, 4),\n",
    "}\n",
    "\n",
    "# Initialiser RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(net, params_dist, refit=True, cv=5, random_state=seed, scoring='neg_mean_squared_error', verbose=3, n_iter=10)\n",
    "\n",
    "# Entraîner le modèle avec GridSearch\n",
    "random_grid_result = random_search.fit(X_train_tensor, y_train_tensor)\n",
    "nouveau_model = random_grid_result.best_estimator_\n",
    "print(\"Best MSE: %f using %s\" % (random_grid_result.best_score_, random_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T17:10:15.282963Z",
     "iopub.status.busy": "2024-12-18T17:10:15.282542Z",
     "iopub.status.idle": "2024-12-18T17:10:15.307765Z",
     "shell.execute_reply": "2024-12-18T17:10:15.306565Z",
     "shell.execute_reply.started": "2024-12-18T17:10:15.282927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred contains NaN: False\n",
      "MSE : 17.89531156494539\n",
      "t_score test : 0.9259615384615385\n",
      "t_score train : 0.85\n"
     ]
    }
   ],
   "source": [
    "y_pred = nouveau_model.predict(X_valid_tensor)\n",
    "y_pred_train = nouveau_model.predict(X_train_tensor)\n",
    "predictions = nouveau_model.predict(X_test_tensor)*100\n",
    "\n",
    "# Vérifiez les sorties du modèle\n",
    "print(\"y_pred contains NaN:\", np.isnan(y_pred).any())\n",
    "# Calculer la MSE\n",
    "mse = np.mean(((y_pred - y_valid)*100)**2)\n",
    "print(\"MSE :\", mse)\n",
    "\n",
    "# Calculer le t_score\n",
    "train_score = np.mean(np.abs(y_pred_train-y_train)*100<=5)\n",
    "test_score = np.mean(np.abs(y_pred-y_valid)*100<=5)\n",
    "print(\"t_score test :\", train_score)\n",
    "print(\"t_score train :\", test_score)\n",
    "\n",
    "ids = np.arange(1, len(predictions) + 1)\n",
    "\n",
    "# Create a DataFrame for the output\n",
    "output_df = pd.DataFrame({\n",
    "\n",
    "    'ID': ids,\n",
    "\n",
    "    'PURITY': predictions\n",
    "\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6324471,
     "sourceId": 10229122,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6324474,
     "sourceId": 10229125,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
