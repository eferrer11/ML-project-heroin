{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1620.5</th>\n",
       "      <th>1626.6</th>\n",
       "      <th>1632.8</th>\n",
       "      <th>1639</th>\n",
       "      <th>1645.2</th>\n",
       "      <th>1651.4</th>\n",
       "      <th>1657.6</th>\n",
       "      <th>1663.8</th>\n",
       "      <th>1670</th>\n",
       "      <th>1676.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.033235</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>0.061383</td>\n",
       "      <td>0.068823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093002</td>\n",
       "      <td>0.099668</td>\n",
       "      <td>0.108805</td>\n",
       "      <td>0.117120</td>\n",
       "      <td>0.121947</td>\n",
       "      <td>0.125137</td>\n",
       "      <td>0.128688</td>\n",
       "      <td>0.133501</td>\n",
       "      <td>0.138187</td>\n",
       "      <td>0.140248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>0.090485</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>0.109033</td>\n",
       "      <td>0.113411</td>\n",
       "      <td>0.117053</td>\n",
       "      <td>0.121665</td>\n",
       "      <td>0.128366</td>\n",
       "      <td>0.134636</td>\n",
       "      <td>0.136961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357223</td>\n",
       "      <td>0.370060</td>\n",
       "      <td>0.386062</td>\n",
       "      <td>0.404460</td>\n",
       "      <td>0.425567</td>\n",
       "      <td>0.450527</td>\n",
       "      <td>0.479066</td>\n",
       "      <td>0.508943</td>\n",
       "      <td>0.539349</td>\n",
       "      <td>0.564486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350973</td>\n",
       "      <td>0.366094</td>\n",
       "      <td>0.384536</td>\n",
       "      <td>0.405034</td>\n",
       "      <td>0.426582</td>\n",
       "      <td>0.450564</td>\n",
       "      <td>0.477045</td>\n",
       "      <td>0.504142</td>\n",
       "      <td>0.531764</td>\n",
       "      <td>0.553650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133917</td>\n",
       "      <td>0.138535</td>\n",
       "      <td>0.145144</td>\n",
       "      <td>0.151008</td>\n",
       "      <td>0.153738</td>\n",
       "      <td>0.155602</td>\n",
       "      <td>0.158525</td>\n",
       "      <td>0.163138</td>\n",
       "      <td>0.167623</td>\n",
       "      <td>0.169048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007995</td>\n",
       "      <td>-0.004902</td>\n",
       "      <td>-0.001237</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.039568</td>\n",
       "      <td>0.046056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052178</td>\n",
       "      <td>0.056051</td>\n",
       "      <td>0.060666</td>\n",
       "      <td>0.066257</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>0.106288</td>\n",
       "      <td>0.117307</td>\n",
       "      <td>0.126626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>0.101527</td>\n",
       "      <td>0.111090</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>0.124868</td>\n",
       "      <td>0.128340</td>\n",
       "      <td>0.132605</td>\n",
       "      <td>0.138737</td>\n",
       "      <td>0.144825</td>\n",
       "      <td>0.148246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.089156</td>\n",
       "      <td>0.097976</td>\n",
       "      <td>0.106049</td>\n",
       "      <td>0.110971</td>\n",
       "      <td>0.114777</td>\n",
       "      <td>0.119445</td>\n",
       "      <td>0.125784</td>\n",
       "      <td>0.132106</td>\n",
       "      <td>0.135891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...    1620.5  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.003972   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.093002   \n",
       "2     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.083369   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.357223   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.350973   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "1295  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.133917   \n",
       "1296  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.007995   \n",
       "1297  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.052178   \n",
       "1298  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.094620   \n",
       "1299  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.082725   \n",
       "\n",
       "        1626.6    1632.8      1639    1645.2    1651.4    1657.6    1663.8  \\\n",
       "0     0.007906  0.012490  0.018123  0.025070  0.033235  0.042502  0.052237   \n",
       "1     0.099668  0.108805  0.117120  0.121947  0.125137  0.128688  0.133501   \n",
       "2     0.090485  0.100462  0.109033  0.113411  0.117053  0.121665  0.128366   \n",
       "3     0.370060  0.386062  0.404460  0.425567  0.450527  0.479066  0.508943   \n",
       "4     0.366094  0.384536  0.405034  0.426582  0.450564  0.477045  0.504142   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1295  0.138535  0.145144  0.151008  0.153738  0.155602  0.158525  0.163138   \n",
       "1296 -0.004902 -0.001237  0.003390  0.009303  0.016472  0.023843  0.031736   \n",
       "1297  0.056051  0.060666  0.066257  0.073435  0.083057  0.094621  0.106288   \n",
       "1298  0.101527  0.111090  0.119861  0.124868  0.128340  0.132605  0.138737   \n",
       "1299  0.089156  0.097976  0.106049  0.110971  0.114777  0.119445  0.125784   \n",
       "\n",
       "          1670    1676.2  \n",
       "0     0.061383  0.068823  \n",
       "1     0.138187  0.140248  \n",
       "2     0.134636  0.136961  \n",
       "3     0.539349  0.564486  \n",
       "4     0.531764  0.553650  \n",
       "...        ...       ...  \n",
       "1295  0.167623  0.169048  \n",
       "1296  0.039568  0.046056  \n",
       "1297  0.117307  0.126626  \n",
       "1298  0.144825  0.148246  \n",
       "1299  0.132106  0.135891  \n",
       "\n",
       "[1300 rows x 178 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "X = data.iloc[:, 6:]\n",
    "classifiers = data.iloc[:, 1:4]\n",
    "enc = OneHotEncoder()\n",
    "data_oh = enc.fit_transform(classifiers).toarray()\n",
    "data_oh = pd.DataFrame(data_oh)\n",
    "X = pd.concat([data_oh, X], axis=1)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.585000\n",
      "1       0.186000\n",
      "2       0.198817\n",
      "3       0.525000\n",
      "4       0.489000\n",
      "          ...   \n",
      "1295    0.101000\n",
      "1296    0.449000\n",
      "1297    0.534000\n",
      "1298    0.136000\n",
      "1299    0.196000\n",
      "Name: PURITY, Length: 1300, dtype: float64\n",
      "[0.41552838 0.16514037 0.11152638 0.05714211 0.04971209 0.03813631\n",
      " 0.03480404 0.02064408 0.01245043 0.00957444 0.00776663 0.0058306\n",
      " 0.00564614 0.00517384 0.00510526 0.00369527]\n"
     ]
    }
   ],
   "source": [
    "#spectrum_filtered = pd.DataFrame(savgol_filter(spectrum, 7, 3, deriv = 2, axis = 0))\n",
    "#spectrum_filtered_st = zscore(spectrum_filtered, axis = 1)\n",
    "\n",
    "y = data[\"PURITY\"]/100\n",
    "print(y)\n",
    "\n",
    "X.columns = X.columns.astype(str)\n",
    "\n",
    "pca = PCA(n_components=16)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "X_train_standardized = standardizer.fit_transform(X_train)\n",
    "X_valid_standardized = standardizer.transform(X_valid)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_standardized, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_valid_tensor = torch.tensor(X_valid_standardized, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X, dtype=torch.float32)\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_tensor = torch.tensor(X).clone().detach().float()\n",
      "/var/folders/93/xgf_b79s5sd1vjn_794f14ym0000gn/T/ipykernel_1118/3960602896.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tensor = torch.tensor(y).clone().detach().float()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(net, params, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Entraîner le modèle avec GridSearch\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m nouveau_model \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MSE: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (grid_result\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[18], line 43\u001b[0m, in \u001b[0;36mNeuralNetRegressor.fit\u001b[0;34m(self, X, y, do_print)\u001b[0m\n\u001b[1;32m     41\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_X, batch_y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_X)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, batch_y)  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/torch/optim/optimizer.py:815\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    813\u001b[0m     per_device_and_dtype_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_profile_name):\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/torch/autograd/profiler.py:605\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Définir le modèle de réseau de neurones simple\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, fc1_out_features=50, fc2_out_features=1, dropout_rate=0.2):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, fc1_out_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(fc1_out_features, fc2_out_features)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(fc2_out_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.silu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.silu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Définir la classe NeuralNetRegressor\n",
    "class NeuralNetRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, input_size, eta=0.001, max_epochs=100, fc1_out_features=50, fc2_out_features=1, batch=10, dropout_rate = 0.5):\n",
    "        self.input_size = input_size\n",
    "        self.eta = eta\n",
    "        self.max_epochs = max_epochs\n",
    "        self.fc1_out_features = fc1_out_features\n",
    "        self.fc2_out_features = fc2_out_features\n",
    "        self.batch = batch\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = SimpleNN(input_size, fc1_out_features, fc2_out_features)\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def fit(self, X, y, do_print=False):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.eta)\n",
    "        X_tensor = torch.tensor(X).clone().detach().float()\n",
    "        y_tensor = torch.tensor(y).clone().detach().float()\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch, shuffle=True)\n",
    "        self.model.train()\n",
    "        # Training loop\n",
    "        for epoch in range(self.max_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                optimizer.zero_grad()  # Reset gradients\n",
    "                outputs = self.model(batch_X)  # Forward pass\n",
    "                loss = self.criterion(outputs, batch_y)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update parameters\n",
    "                epoch_loss += loss.item()\n",
    "            if do_print:\n",
    "                print(f\"Epoch {epoch+1}/{self.max_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.model.eval()\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(X_tensor).flatten()\n",
    "        return outputs.numpy()\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "# Initialiser le modèle\n",
    "input_size = X_train_tensor.shape[1]\n",
    "net = NeuralNetRegressor(input_size=input_size)\n",
    "\n",
    "# Définir les paramètres pour GridSearch\n",
    "params = {\n",
    "    'eta': [0.0005, 0.001],\n",
    "    'max_epochs': [50],\n",
    "    'fc1_out_features': [32, 64, 128],\n",
    "    'fc2_out_features': [32, 64, 128],\n",
    "    'batch': [65, 70],\n",
    "    'dropout_rate': [0.3, 0.4, 0.5]\n",
    "}\n",
    "\n",
    "# Initialiser GridSearchCV\n",
    "grid_search = GridSearchCV(net, params, refit=True, cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "\n",
    "# Entraîner le modèle avec GridSearch\n",
    "grid_result = grid_search.fit(X_train_tensor, y_train_tensor)\n",
    "nouveau_model = grid_result.best_estimator_\n",
    "\n",
    "print(\"Best MSE: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid_tensor contains NaN: False\n",
      "y_valid_tensor contains NaN: False\n",
      "y_pred contains NaN: False\n",
      "MSE : 0.0055522863\n",
      "t_score test : 1.0\n",
      "t_score train : 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = nouveau_model.predict(X_valid_tensor)\n",
    "y_pred_train=nouveau_model.predict(X_train_tensor)\n",
    "\n",
    "# Vérifiez les sorties du modèle\n",
    "print(\"y_pred contains NaN:\", np.isnan(y_pred).any())\n",
    "\n",
    "# Calculer la MSE\n",
    "mse = np.mean(((y_pred - y_valid)*100)**2)\n",
    "print(\"MSE :\", mse)\n",
    "\n",
    "# Calculer le t_score\n",
    "train_score = np.mean(np.abs((y_pred_train-y_train)*100<=5))\n",
    "test_score = np.mean(np.abs((y_pred-y_valid)*100<=5))\n",
    "print(\"t_score test :\", train_score)\n",
    "print(\"t_score train :\", test_score)\n",
    "\n",
    "\"\"\"\n",
    "# Afficher la courbe d'apprentissage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steps, learning_curve)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
