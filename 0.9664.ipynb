{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('./'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also writ"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "./.amlignore\n./.amlignore.amltmp\n./0.99.ipynb\n./0.99.ipynb.amltmp\n./0.99_orig.ipynb\n./0.99_orig.ipynb.amltmp\n./plot.ipynb\n./plot.ipynb.amltmp\n./predictions.csv\n./substances.csv\n./test.csv\n./train.csv\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-18-20-34-41Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-18-21-43-44Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-18-22-31-27Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-18-22-34-50Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-18-22-35-3Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-19-11-31-26Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-19-13-2-6Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-19-14-16-15Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-19-15-18-37Z.ipynb\n./.ipynb_aml_checkpoints/0.99-checkpoint2024-11-19-8-21-51Z.ipynb\n./.ipynb_aml_checkpoints/0.99_orig-checkpoint2024-11-19-11-27-33Z.ipynb\n./.ipynb_aml_checkpoints/0.99_orig-checkpoint2024-11-19-11-33-19Z.ipynb\n./.ipynb_aml_checkpoints/0.99_orig-checkpoint2024-11-19-13-1-46Z.ipynb\n./.ipynb_aml_checkpoints/plot-checkpoint2024-11-18-21-23-45Z.ipynb\n./.ipynb_aml_checkpoints/plot-checkpoint2024-11-18-22-9-57Z.ipynb\n./.ipynb_aml_checkpoints/plot-checkpoint2024-11-19-11-33-22Z.ipynb\n./.ipynb_aml_checkpoints/plot-checkpoint2024-11-19-13-53-31Z.ipynb\n./.ipynb_aml_checkpoints/plot-checkpoint2024-11-19-8-33-44Z.ipynb\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-17T18:22:37.504315Z",
          "iopub.execute_input": "2024-12-17T18:22:37.504760Z",
          "iopub.status.idle": "2024-12-17T18:22:37.517679Z",
          "shell.execute_reply.started": "2024-12-17T18:22:37.504723Z",
          "shell.execute_reply": "2024-12-17T18:22:37.516327Z"
        },
        "gather": {
          "logged": 1734622586124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.decomposition import PCA\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from scipy.stats import uniform, randint, loguniform\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:09:20.150910Z",
          "iopub.execute_input": "2024-12-18T16:09:20.152085Z",
          "iopub.status.idle": "2024-12-18T16:09:20.159233Z",
          "shell.execute_reply.started": "2024-12-18T16:09:20.152034Z",
          "shell.execute_reply": "2024-12-18T16:09:20.157822Z"
        },
        "gather": {
          "logged": 1734622588108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"./train.csv\")\n",
        "data_test = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "X_train = data_train.iloc[:, 6:].values\n",
        "X_test = data_test.iloc[:, 5:].values"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:09:23.035408Z",
          "iopub.execute_input": "2024-12-18T16:09:23.035897Z",
          "iopub.status.idle": "2024-12-18T16:09:23.105241Z",
          "shell.execute_reply.started": "2024-12-18T16:09:23.035854Z",
          "shell.execute_reply": "2024-12-18T16:09:23.104091Z"
        },
        "gather": {
          "logged": 1734622588951
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "          sample_name device_serial  substance_form_display  \\\n0            11140009    M1-1000112      Homogenized Powder   \n1     22.0401-P002.02    M1-1000109  Non homogenized powder   \n2     22.0117-P001.02    M1-1000100  Non homogenized powder   \n3        20.0163-P009      N1-00196             Unspecified   \n4        19.0286-P005      N1-00196             Unspecified   \n...               ...           ...                     ...   \n1295  22.0267-P001.01    M1-1000100      Homogenized Powder   \n1296         11060000    M1-1000144      Homogenized Powder   \n1297     22.0368-P002    M1-1000130      Homogenized Powder   \n1298  22.0342-P002.04    M1-1000109      Homogenized Powder   \n1299  22.0401-P001.04    M1-1000109      Homogenized Powder   \n\n     measure_type_display prod_substance     PURITY     908.1     914.3  \\\n0          Direct contact         Heroin  58.500000  0.044734  0.042720   \n1          Direct contact         Heroin  18.600000  0.063695  0.056980   \n2          Direct contact         Heroin  19.881719  0.050358  0.044910   \n3          Direct contact         Heroin  52.500000  0.525050  0.520434   \n4          Direct contact         Heroin  48.900000  0.479365  0.467401   \n...                   ...            ...        ...       ...       ...   \n1295       Direct contact         Heroin  10.100000  0.107930  0.103983   \n1296       Direct contact         Heroin  44.900000  0.040564  0.041559   \n1297       Direct contact         Heroin  53.400000  0.106459  0.108084   \n1298       Direct contact         Heroin  13.600000  0.075628  0.068853   \n1299       Direct contact         Heroin  19.600000  0.058483  0.051543   \n\n         920.5     926.7  ...    1620.5    1626.6    1632.8      1639  \\\n0     0.041361  0.040055  ...  0.003972  0.007906  0.012490  0.018123   \n1     0.050080  0.043339  ...  0.093002  0.099668  0.108805  0.117120   \n2     0.039148  0.033730  ...  0.083369  0.090485  0.100462  0.109033   \n3     0.517187  0.516377  ...  0.357223  0.370060  0.386062  0.404460   \n4     0.456680  0.446148  ...  0.350973  0.366094  0.384536  0.405034   \n...        ...       ...  ...       ...       ...       ...       ...   \n1295  0.100068  0.096422  ...  0.133917  0.138535  0.145144  0.151008   \n1296  0.042435  0.043870  ... -0.007995 -0.004902 -0.001237  0.003390   \n1297  0.109983  0.109541  ...  0.052178  0.056051  0.060666  0.066257   \n1298  0.062538  0.056079  ...  0.094620  0.101527  0.111090  0.119861   \n1299  0.044479  0.037586  ...  0.082725  0.089156  0.097976  0.106049   \n\n        1645.2    1651.4    1657.6    1663.8      1670    1676.2  \n0     0.025070  0.033235  0.042502  0.052237  0.061383  0.068823  \n1     0.121947  0.125137  0.128688  0.133501  0.138187  0.140248  \n2     0.113411  0.117053  0.121665  0.128366  0.134636  0.136961  \n3     0.425567  0.450527  0.479066  0.508943  0.539349  0.564486  \n4     0.426582  0.450564  0.477045  0.504142  0.531764  0.553650  \n...        ...       ...       ...       ...       ...       ...  \n1295  0.153738  0.155602  0.158525  0.163138  0.167623  0.169048  \n1296  0.009303  0.016472  0.023843  0.031736  0.039568  0.046056  \n1297  0.073435  0.083057  0.094621  0.106288  0.117307  0.126626  \n1298  0.124868  0.128340  0.132605  0.138737  0.144825  0.148246  \n1299  0.110971  0.114777  0.119445  0.125784  0.132106  0.135891  \n\n[1300 rows x 131 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_name</th>\n      <th>device_serial</th>\n      <th>substance_form_display</th>\n      <th>measure_type_display</th>\n      <th>prod_substance</th>\n      <th>PURITY</th>\n      <th>908.1</th>\n      <th>914.3</th>\n      <th>920.5</th>\n      <th>926.7</th>\n      <th>...</th>\n      <th>1620.5</th>\n      <th>1626.6</th>\n      <th>1632.8</th>\n      <th>1639</th>\n      <th>1645.2</th>\n      <th>1651.4</th>\n      <th>1657.6</th>\n      <th>1663.8</th>\n      <th>1670</th>\n      <th>1676.2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11140009</td>\n      <td>M1-1000112</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>58.500000</td>\n      <td>0.044734</td>\n      <td>0.042720</td>\n      <td>0.041361</td>\n      <td>0.040055</td>\n      <td>...</td>\n      <td>0.003972</td>\n      <td>0.007906</td>\n      <td>0.012490</td>\n      <td>0.018123</td>\n      <td>0.025070</td>\n      <td>0.033235</td>\n      <td>0.042502</td>\n      <td>0.052237</td>\n      <td>0.061383</td>\n      <td>0.068823</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.0401-P002.02</td>\n      <td>M1-1000109</td>\n      <td>Non homogenized powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>18.600000</td>\n      <td>0.063695</td>\n      <td>0.056980</td>\n      <td>0.050080</td>\n      <td>0.043339</td>\n      <td>...</td>\n      <td>0.093002</td>\n      <td>0.099668</td>\n      <td>0.108805</td>\n      <td>0.117120</td>\n      <td>0.121947</td>\n      <td>0.125137</td>\n      <td>0.128688</td>\n      <td>0.133501</td>\n      <td>0.138187</td>\n      <td>0.140248</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22.0117-P001.02</td>\n      <td>M1-1000100</td>\n      <td>Non homogenized powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>19.881719</td>\n      <td>0.050358</td>\n      <td>0.044910</td>\n      <td>0.039148</td>\n      <td>0.033730</td>\n      <td>...</td>\n      <td>0.083369</td>\n      <td>0.090485</td>\n      <td>0.100462</td>\n      <td>0.109033</td>\n      <td>0.113411</td>\n      <td>0.117053</td>\n      <td>0.121665</td>\n      <td>0.128366</td>\n      <td>0.134636</td>\n      <td>0.136961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20.0163-P009</td>\n      <td>N1-00196</td>\n      <td>Unspecified</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>52.500000</td>\n      <td>0.525050</td>\n      <td>0.520434</td>\n      <td>0.517187</td>\n      <td>0.516377</td>\n      <td>...</td>\n      <td>0.357223</td>\n      <td>0.370060</td>\n      <td>0.386062</td>\n      <td>0.404460</td>\n      <td>0.425567</td>\n      <td>0.450527</td>\n      <td>0.479066</td>\n      <td>0.508943</td>\n      <td>0.539349</td>\n      <td>0.564486</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19.0286-P005</td>\n      <td>N1-00196</td>\n      <td>Unspecified</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>48.900000</td>\n      <td>0.479365</td>\n      <td>0.467401</td>\n      <td>0.456680</td>\n      <td>0.446148</td>\n      <td>...</td>\n      <td>0.350973</td>\n      <td>0.366094</td>\n      <td>0.384536</td>\n      <td>0.405034</td>\n      <td>0.426582</td>\n      <td>0.450564</td>\n      <td>0.477045</td>\n      <td>0.504142</td>\n      <td>0.531764</td>\n      <td>0.553650</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1295</th>\n      <td>22.0267-P001.01</td>\n      <td>M1-1000100</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>10.100000</td>\n      <td>0.107930</td>\n      <td>0.103983</td>\n      <td>0.100068</td>\n      <td>0.096422</td>\n      <td>...</td>\n      <td>0.133917</td>\n      <td>0.138535</td>\n      <td>0.145144</td>\n      <td>0.151008</td>\n      <td>0.153738</td>\n      <td>0.155602</td>\n      <td>0.158525</td>\n      <td>0.163138</td>\n      <td>0.167623</td>\n      <td>0.169048</td>\n    </tr>\n    <tr>\n      <th>1296</th>\n      <td>11060000</td>\n      <td>M1-1000144</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>44.900000</td>\n      <td>0.040564</td>\n      <td>0.041559</td>\n      <td>0.042435</td>\n      <td>0.043870</td>\n      <td>...</td>\n      <td>-0.007995</td>\n      <td>-0.004902</td>\n      <td>-0.001237</td>\n      <td>0.003390</td>\n      <td>0.009303</td>\n      <td>0.016472</td>\n      <td>0.023843</td>\n      <td>0.031736</td>\n      <td>0.039568</td>\n      <td>0.046056</td>\n    </tr>\n    <tr>\n      <th>1297</th>\n      <td>22.0368-P002</td>\n      <td>M1-1000130</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>53.400000</td>\n      <td>0.106459</td>\n      <td>0.108084</td>\n      <td>0.109983</td>\n      <td>0.109541</td>\n      <td>...</td>\n      <td>0.052178</td>\n      <td>0.056051</td>\n      <td>0.060666</td>\n      <td>0.066257</td>\n      <td>0.073435</td>\n      <td>0.083057</td>\n      <td>0.094621</td>\n      <td>0.106288</td>\n      <td>0.117307</td>\n      <td>0.126626</td>\n    </tr>\n    <tr>\n      <th>1298</th>\n      <td>22.0342-P002.04</td>\n      <td>M1-1000109</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>13.600000</td>\n      <td>0.075628</td>\n      <td>0.068853</td>\n      <td>0.062538</td>\n      <td>0.056079</td>\n      <td>...</td>\n      <td>0.094620</td>\n      <td>0.101527</td>\n      <td>0.111090</td>\n      <td>0.119861</td>\n      <td>0.124868</td>\n      <td>0.128340</td>\n      <td>0.132605</td>\n      <td>0.138737</td>\n      <td>0.144825</td>\n      <td>0.148246</td>\n    </tr>\n    <tr>\n      <th>1299</th>\n      <td>22.0401-P001.04</td>\n      <td>M1-1000109</td>\n      <td>Homogenized Powder</td>\n      <td>Direct contact</td>\n      <td>Heroin</td>\n      <td>19.600000</td>\n      <td>0.058483</td>\n      <td>0.051543</td>\n      <td>0.044479</td>\n      <td>0.037586</td>\n      <td>...</td>\n      <td>0.082725</td>\n      <td>0.089156</td>\n      <td>0.097976</td>\n      <td>0.106049</td>\n      <td>0.110971</td>\n      <td>0.114777</td>\n      <td>0.119445</td>\n      <td>0.125784</td>\n      <td>0.132106</td>\n      <td>0.135891</td>\n    </tr>\n  </tbody>\n</table>\n<p>1300 rows × 131 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622590953
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "cumvariance = np.cumsum(pca.explained_variance_ratio_)\n",
        "cumvariance"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "array([0.86338598, 0.98281272, 0.99711247, 0.99910158, 0.99959773,\n       0.99975821, 0.99985687, 0.99990601, 0.99993958, 0.99995823,\n       0.99997198, 0.99998013, 0.99998455, 0.9999882 , 0.99999078,\n       0.99999284, 0.99999461, 0.99999564, 0.99999645, 0.9999971 ,\n       0.99999753, 0.99999789, 0.99999824, 0.9999985 , 0.99999873,\n       0.99999892, 0.99999902, 0.99999913, 0.99999921, 0.99999929,\n       0.99999934, 0.9999994 , 0.99999944, 0.99999948, 0.99999952,\n       0.99999955, 0.99999958, 0.99999961, 0.99999963, 0.99999966,\n       0.99999968, 0.9999997 , 0.99999972, 0.99999974, 0.99999975,\n       0.99999977, 0.99999978, 0.9999998 , 0.99999981, 0.99999982,\n       0.99999983, 0.99999984, 0.99999985, 0.99999986, 0.99999987,\n       0.99999988, 0.99999988, 0.99999989, 0.9999999 , 0.9999999 ,\n       0.99999991, 0.99999991, 0.99999992, 0.99999992, 0.99999993,\n       0.99999993, 0.99999994, 0.99999994, 0.99999994, 0.99999995,\n       0.99999995, 0.99999995, 0.99999995, 0.99999996, 0.99999996,\n       0.99999996, 0.99999996, 0.99999996, 0.99999997, 0.99999997,\n       0.99999997, 0.99999997, 0.99999997, 0.99999998, 0.99999998,\n       0.99999998, 0.99999998, 0.99999998, 0.99999998, 0.99999998,\n       0.99999998, 0.99999999, 0.99999999, 0.99999999, 0.99999999,\n       0.99999999, 0.99999999, 0.99999999, 0.99999999, 0.99999999,\n       0.99999999, 0.99999999, 0.99999999, 0.99999999, 0.99999999,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ,\n       1.        , 1.        , 1.        , 1.        , 1.        ])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622593315
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep 99% of variance\n",
        "#n_comp = np.where(cumvariance>0.99)[0][0]\n",
        "#n_comp"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734621452025
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pure = pd.read_csv(\"./substances.csv\")\n",
        "# #pure = pure[pure[\"substance\"].str.contains(\"heroin\")]\n",
        "# pure = pure.iloc[:,1:].values\n",
        "# pure.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734614629623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_normalized = preprocessing.normalize(X_train, axis=1)\n",
        "# pure_normalized = preprocessing.normalize(pure, axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734614632173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_normalized.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734614636086
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_normalized = X_normalized @ pure_normalized.T\n",
        "# X_normalized.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734614640634
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pca = PCA()\n",
        "# pca.fit(X_normalized)\n",
        "# np.cumsum(pca.explained_variance_ratio_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734614645598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data_train.iloc[:,5:6].values/100\n",
        "y.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(1300, 1)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622600245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed = 43\n",
        "\"\"\"\n",
        "# Combine original data with PCA components\n",
        "standardizer = StandardScaler()\n",
        "X_st = standardizer.fit_transform(X_train)\n",
        "\"\"\"\n",
        "## Perform PCA to retain 99% of the variance\n",
        "pca = PCA()\n",
        "pca.fit(X_train)\n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "#X_normalized = preprocessing.normalize(X_pca)\n",
        "#X_normalized = X_train\n",
        "\n",
        "\n",
        "# Standardisation des données (avant PCA)\n",
        "#scaler = StandardScaler()\n",
        "#X_train = scaler.fit_transform(X_train)\n",
        "#X_test = scaler.transform(X_test)\n",
        "\n",
        "#X_train, X_valid, y_train, y_valid = train_test_split(X_normalized, y, test_size=0.2, random_state = 42)\n",
        "\n",
        "# Convert to tensors\n",
        "#X_train_tensor = torch.tensor(X_train, dtype=torch.float32).clone().detach()\n",
        "#y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1).clone().detach()\n",
        "#X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32).clone().detach()\n",
        "#y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).reshape(-1, 1).clone().detach()"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:09:26.284698Z",
          "iopub.execute_input": "2024-12-18T16:09:26.285133Z",
          "iopub.status.idle": "2024-12-18T16:09:26.740096Z",
          "shell.execute_reply.started": "2024-12-18T16:09:26.285094Z",
          "shell.execute_reply": "2024-12-18T16:09:26.738862Z"
        },
        "gather": {
          "logged": 1734622615971
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "array([[-4.70200365e-01, -3.83971275e-01,  3.78512968e-02, ...,\n        -1.54638703e-05,  2.61830668e-06,  2.29016815e-06],\n       [-2.47416291e-01, -5.47927097e-02, -8.79727127e-02, ...,\n         4.79866179e-06, -1.01758180e-05,  1.87281627e-06],\n       [-3.28515012e-01, -6.35064321e-02, -7.65174225e-02, ...,\n        -7.73878857e-06, -2.67699877e-05,  6.73251349e-06],\n       ...,\n       [ 1.47048873e-01, -4.41047301e-01,  4.97612111e-02, ...,\n         5.23901569e-06,  4.25810056e-06, -1.69010730e-05],\n       [-1.99482391e-01, -6.61147111e-02, -5.80451993e-02, ...,\n         1.25530178e-05, -7.16188076e-07,  3.36811338e-06],\n       [-3.21640088e-01, -6.43204801e-02, -7.81904136e-02, ...,\n         1.00189269e-06, -9.71338417e-06, -4.73784684e-06]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622618214
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y\n",
        "y_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([[0.585     ],\n       [0.186     ],\n       [0.19881719],\n       ...,\n       [0.534     ],\n       [0.136     ],\n       [0.196     ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622625276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_pca = pca.transform(X_test)\n",
        "#X_test_normalized = preprocessing.normalize(X_pca)\n",
        "#X_test_normalized = X_test\n",
        "#X_test_tensor = torch.tensor(X_test_normalised, dtype=torch.float32).clone().detach() \n",
        "\n",
        "# X_test_normalized = preprocessing.normalize(X_test.values, axis=1)\n",
        "# X_test_normalized = X_test_normalized @ pure_normalized.T\n",
        "# X_test_normalized.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:09:31.429240Z",
          "iopub.execute_input": "2024-12-18T16:09:31.429856Z",
          "iopub.status.idle": "2024-12-18T16:09:31.447658Z",
          "shell.execute_reply.started": "2024-12-18T16:09:31.429794Z",
          "shell.execute_reply": "2024-12-18T16:09:31.444833Z"
        },
        "gather": {
          "logged": 1734608106926
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_loss(output, target):\n",
        "    loss = torch.maximum(torch.zeros_like(output),(output - target)-.05) + torch.maximum(torch.zeros_like(output),(target - output)-.05)\n",
        "    return torch.mean(loss)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622629448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définir le modèle de réseau de neurones simple\n",
        "\n",
        "class FeedForwardNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, lin_layer_sizes,\n",
        "\n",
        "                 outpout_size, lin_layer_dropouts, activation):\n",
        "        super().__init__()       \n",
        "        if activation == 0:\n",
        "            self.activation = nn.ReLU()\n",
        "        elif activation == 1:\n",
        "            self.activation = nn.SiLU()\n",
        "        elif activation == 2:\n",
        "            self.activation = nn.Tanh()\n",
        "        elif activation == 3:\n",
        "            self.activation = nn.LeakyReLU()  \n",
        "\n",
        "        # Linear Layers\n",
        "        first_lin_layer = nn.Linear(input_size, lin_layer_sizes[0])\n",
        "        self.lin_layers = nn.ModuleList([first_lin_layer] + [nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1]) for i in range(len(lin_layer_sizes) - 1)])     \n",
        "\n",
        "        # Output Layer\n",
        "        self.outpout_layer = nn.Linear(lin_layer_sizes[-1], outpout_size)\n",
        "        \n",
        "        # Dropout Layers\n",
        "        self.dropout_layers = nn.ModuleList([nn.Dropout(rate) for rate,size in zip(lin_layer_dropouts,lin_layer_sizes)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for lin_layer, dropout_layer in zip(self.lin_layers, self.dropout_layers):\n",
        "            x = lin_layer(x)     \n",
        "            x = self.activation(x)\n",
        "            x = dropout_layer(x)\n",
        " \n",
        "        x = self.outpout_layer(x)\n",
        "        x = nn.Sigmoid()(x)\n",
        "  \n",
        "        return x\n",
        "\n",
        "# Définir la classe NeuralNetRegressor\n",
        "class NeuralNetRegressor(BaseEstimator, RegressorMixin):\n",
        "\n",
        "    def __init__(self, input_size, random_state, eta=0.001, max_epochs=100, batch=10, lin_layer_sizes = [50, 50],\n",
        "            outpout_size = 1, lin_layer_dropouts = [0.4, 0.4], activation = 0, loss=0, n_comp=None):\n",
        "\n",
        "        if n_comp is not None:\n",
        "            print(\"n_comp\", n_comp)\n",
        "            self.input_size = n_comp\n",
        "        else:\n",
        "            self.input_size = input_size\n",
        "\n",
        "        self.random_state = random_state\n",
        "        self.eta = eta\n",
        "        self.max_epochs = max_epochs\n",
        "        self.batch = batch\n",
        "        self.lin_layer_sizes = lin_layer_sizes\n",
        "        self.outpout_size = outpout_size\n",
        "        self.lin_layer_dropouts = lin_layer_dropouts\n",
        "        self.activation = activation\n",
        "        self.model = None\n",
        "\n",
        "        self.n_comp = n_comp\n",
        "\n",
        "        self.loss = loss\n",
        "        if loss==0:\n",
        "            self.criterion = nn.MSELoss()\n",
        "        elif loss==1:\n",
        "            self.criterion = nn.L1Loss()\n",
        "        else:\n",
        "            self.criterion = my_loss\n",
        "       \n",
        "    def fit(self, X, y, do_print=False,X_valid=None, y_valid=None ):\n",
        "        #print(\"self.eta\",self.eta)\n",
        "        #print(\"X\",X.shape)\n",
        "        #print(\"Y\",y.shape)\n",
        "\n",
        "        #print(\"FITTING\")\n",
        "\n",
        "        self.model = FeedForwardNN(self.n_comp, self.lin_layer_sizes,\n",
        "                 self.outpout_size, self.lin_layer_dropouts, self.activation)\n",
        "\n",
        "\n",
        "        #print(\"n_comp\", self.n_comp)\n",
        "        if self.n_comp is not None:\n",
        "            X = X[:,:self.n_comp]\n",
        "\n",
        "        #print(\"shape\", X.shape)\n",
        "        \n",
        "        #print(\"model\", self.model)\n",
        "\n",
        "        optimizer = optim.Adam(self.model.parameters(), lr=self.eta)\n",
        "        X_tensor = torch.tensor(X).clone().detach().float()\n",
        "        y_tensor = torch.tensor(y).clone().detach().float()\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=self.batch, shuffle=True)\n",
        "        self.model.train()\n",
        "\n",
        "        if X_valid is not None:\n",
        "            X_valid = torch.tensor(X_valid).clone().detach().float()\n",
        "            y_valid = torch.tensor(y_valid).clone().detach().float()\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(self.max_epochs):\n",
        "\n",
        "            epoch_loss = 0.0\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                optimizer.zero_grad()  # Reset gradients\n",
        "                outputs = self.model(batch_X)  # Forward pass\n",
        "                loss = self.criterion(outputs, batch_y)  # Compute loss\n",
        "                loss.backward()  # Backward pass\n",
        "                optimizer.step()  # Update parameters\n",
        "                epoch_loss += loss.item()\n",
        "            if do_print and X_valid is not None:\n",
        "                outputs = self.model(X_valid)  # Forward pass\n",
        "                valid_loss = self.criterion(outputs, y_valid)  # Compute loss\n",
        "                print(f\"Epoch {epoch+1}/{self.max_epochs}, Loss: {epoch_loss / len(dataloader)}, Valid_loss: {valid_loss}\")\n",
        "\n",
        "            elif do_print:\n",
        "                print(f\"Epoch {epoch+1}/{self.max_epochs}, Loss: {epoch_loss / len(dataloader)}\")\n",
        "\n",
        "        return self  \n",
        "\n",
        "    def predict(self, X):\n",
        "        self.model.eval()\n",
        "        print(\"n_comp\", self.n_comp)\n",
        "        if self.n_comp is not None:\n",
        "            X = X[:,:self.n_comp]\n",
        "\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(X_tensor)\n",
        "        return outputs.numpy()\n",
        "        \n",
        "    def parameters(self):\n",
        "        return self.model.parameters()"
      ],
      "outputs": [],
      "execution_count": 56,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T17:12:26.917904Z",
          "iopub.execute_input": "2024-12-18T17:12:26.918396Z",
          "iopub.status.idle": "2024-12-18T17:12:26.939464Z",
          "shell.execute_reply.started": "2024-12-18T17:12:26.918354Z",
          "shell.execute_reply": "2024-12-18T17:12:26.938046Z"
        },
        "gather": {
          "logged": 1734624656538
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomLayers:\n",
        "    def __init__(self,min_layers, max_layers, min_nodes, max_nodes):\n",
        "        self.min_nodes = min_nodes\n",
        "        self.max_nodes = max_nodes\n",
        "        self.min_layers = min_layers\n",
        "        self.max_layers = max_layers\n",
        "\n",
        "    def rvs(self, random_state=None):\n",
        "        if random_state is not None:\n",
        "            prev = randint.random_state\n",
        "            randint.random_state = random_state \n",
        "\n",
        "        nodes = randint.rvs(self.min_nodes, self.max_nodes)\n",
        "        res = [nodes for _ in range(randint.rvs(self.min_layers, self.max_layers))]\n",
        "\n",
        "        if random_state is not None:\n",
        "            randint.random_state = prev\n",
        "\n",
        "        return res"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:11:58.518750Z",
          "iopub.execute_input": "2024-12-18T16:11:58.519266Z",
          "iopub.status.idle": "2024-12-18T16:11:58.526839Z",
          "shell.execute_reply.started": "2024-12-18T16:11:58.519225Z",
          "shell.execute_reply": "2024-12-18T16:11:58.525704Z"
        },
        "gather": {
          "logged": 1734622644890
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomDropout:\n",
        "    def __init__(self, max_layers,min_dropout,max_dropout):\n",
        "        self.min_dropout = min_dropout\n",
        "        self.max_dropout = max_dropout\n",
        "        self.max_layers = max_layers\n",
        "\n",
        "    def rvs(self, random_state=None):\n",
        "        if random_state is not None:\n",
        "            prev = uniform.random_state\n",
        "            uniform.random_state = random_state \n",
        "        dropout = uniform.rvs(self.min_dropout, self.max_dropout)\n",
        "        res = [dropout for _ in range(self.max_layers)]\n",
        "\n",
        "        if random_state is not None:\n",
        "            uniform.random_state = prev\n",
        "\n",
        "        return res"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T16:12:01.048945Z",
          "iopub.execute_input": "2024-12-18T16:12:01.049358Z",
          "iopub.status.idle": "2024-12-18T16:12:01.056862Z",
          "shell.execute_reply.started": "2024-12-18T16:12:01.049313Z",
          "shell.execute_reply": "2024-12-18T16:12:01.055552Z"
        },
        "gather": {
          "logged": 1734622646660
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def my_custom_score(ground_truth, predictions):\n",
        "    return np.mean(np.abs(predictions-ground_truth)*100<=5)\n",
        "\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "scorer = make_scorer(my_custom_score, greater_is_better=True)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622648012
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:,:3]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "array([[-0.47020036, -0.38397127,  0.0378513 ],\n       [-0.24741629, -0.05479271, -0.08797271],\n       [-0.32851501, -0.06350643, -0.07651742],\n       ...,\n       [ 0.14704887, -0.4410473 ,  0.04976121],\n       [-0.19948239, -0.06611471, -0.0580452 ],\n       [-0.32164009, -0.06432048, -0.07819041]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734622920476
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialiser le modèle\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "input_size = X_train.shape[1]\n",
        "net = NeuralNetRegressor(input_size=input_size, random_state=seed)\n",
        "\n",
        "max_layers = 5\n",
        "\n",
        "# Définir les paramètres pour GridSearch\n",
        "params_dist = {\n",
        "\n",
        "    'eta': loguniform(1e-4, 1e-1),\n",
        "    'max_epochs': randint(10, 500),\n",
        "    'batch': randint(8, 64),\n",
        "    'lin_layer_sizes': RandomLayers(1,max_layers,4,256),  # Taille de 1 à 4 couches, entre 4 et 256 neurones par couche\n",
        "    'lin_layer_dropouts': RandomDropout(max_layers,0.,.5),\n",
        "    'activation': randint(0, 4),\n",
        "    'loss': randint(0, 3),\n",
        "    'n_comp': randint(1, X_train.shape[1]),\n",
        "}\n",
        "\n",
        "# Initialiser RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(net, params_dist, refit=True, cv=5, random_state=seed, scoring=scorer, verbose=3, n_iter=30, n_jobs=-2)\n",
        "\n",
        "# Entraîner le modèle avec GridSearch\n",
        "random_grid_result = random_search.fit(X_train, y_train)\n",
        "nouveau_model = random_grid_result.best_estimator_\n",
        "print(\"Best score: %f using %s\" % (random_grid_result.best_score_, random_grid_result.best_params_))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Fitting 5 folds for each of 30 candidates, totalling 150 fits\nFITTING\nn_comp 53\nshape (1040, 53)\nmodel FeedForwardNN(\n  (activation): Tanh()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=53, out_features=107, bias=True)\n    (1-3): 3 x Linear(in_features=107, out_features=107, bias=True)\n  )\n  (outpout_layer): Linear(in_features=107, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.16685430556951092, inplace=False)\n  )\n)\nn_comp 53\n[CV 3/5] END activation=2, batch=18, eta=0.0023864188780056052, lin_layer_dropouts=[0.16685430556951092, 0.16685430556951092, 0.16685430556951092, 0.16685430556951092, 0.16685430556951092], lin_layer_sizes=[107, 107, 107, 107], loss=2, max_epochs=159, n_comp=53;, score=0.935 total time=  35.5s\nFITTING\nn_comp 89\nshape (1040, 89)\nmodel FeedForwardNN(\n  (activation): ReLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=89, out_features=76, bias=True)\n    (1-2): 2 x Linear(in_features=76, out_features=76, bias=True)\n  )\n  (outpout_layer): Linear(in_features=76, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.34015376929388985, inplace=False)\n  )\n)\nn_comp 89\n[CV 4/5] END activation=0, batch=10, eta=0.038003292140451964, lin_layer_dropouts=[0.34015376929388985, 0.34015376929388985, 0.34015376929388985, 0.34015376929388985, 0.34015376929388985], lin_layer_sizes=[76, 76, 76], loss=1, max_epochs=397, n_comp=89;, score=0.500 total time= 1.9min\nFITTING\nn_comp 88\nshape (1040, 88)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=88, out_features=68, bias=True)\n  )\n  (outpout_layer): Linear(in_features=68, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.40109849037701983, inplace=False)\n  )\n)\nn_comp 88\n[CV 1/5] END activation=3, batch=52, eta=0.00026471141828218156, lin_layer_dropouts=[0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983], lin_layer_sizes=[68], loss=2, max_epochs=18, n_comp=88;, score=0.108 total time=   0.8s\nFITTING\nn_comp 88\nshape (1040, 88)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=88, out_features=68, bias=True)\n  )\n  (outpout_layer): Linear(in_features=68, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.40109849037701983, inplace=False)\n  )\n)\nn_comp 88\n[CV 2/5] END activation=3, batch=52, eta=0.00026471141828218156, lin_layer_dropouts=[0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983], lin_layer_sizes=[68], loss=2, max_epochs=18, n_comp=88;, score=0.104 total time=   0.8s\nFITTING\nn_comp 88\nshape (1040, 88)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=88, out_features=68, bias=True)\n  )\n  (outpout_layer): Linear(in_features=68, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.40109849037701983, inplace=False)\n  )\n)\nn_comp 88\n[CV 3/5] END activation=3, batch=52, eta=0.00026471141828218156, lin_layer_dropouts=[0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983], lin_layer_sizes=[68], loss=2, max_epochs=18, n_comp=88;, score=0.119 total time=   0.9s\nFITTING\nn_comp 88\nshape (1040, 88)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=88, out_features=68, bias=True)\n  )\n  (outpout_layer): Linear(in_features=68, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.40109849037701983, inplace=False)\n  )\n)\nn_comp 88\n[CV 4/5] END activation=3, batch=52, eta=0.00026471141828218156, lin_layer_dropouts=[0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983], lin_layer_sizes=[68], loss=2, max_epochs=18, n_comp=88;, score=0.100 total time=   0.8s\nFITTING\nn_comp 88\nshape (1040, 88)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=88, out_features=68, bias=True)\n  )\n  (outpout_layer): Linear(in_features=68, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.40109849037701983, inplace=False)\n  )\n)\nn_comp 88\n[CV 5/5] END activation=3, batch=52, eta=0.00026471141828218156, lin_layer_dropouts=[0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983, 0.40109849037701983], lin_layer_sizes=[68], loss=2, max_epochs=18, n_comp=88;, score=0.127 total time=   0.8s\nFITTING\nn_comp 33\nshape (1040, 33)\nmodel FeedForwardNN(\n  (activation): ReLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=33, out_features=246, bias=True)\n  )\n  (outpout_layer): Linear(in_features=246, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.007039911357542228, inplace=False)\n  )\n)\nn_comp 33\n[CV 1/5] END activation=0, batch=51, eta=0.0007593893885357789, lin_layer_dropouts=[0.007039911357542228, 0.007039911357542228, 0.007039911357542228, 0.007039911357542228, 0.007039911357542228], lin_layer_sizes=[246], loss=2, max_epochs=428, n_comp=33;, score=0.977 total time=  21.0s\nFITTING\nn_comp 104\nshape (1040, 104)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=104, out_features=219, bias=True)\n  )\n  (outpout_layer): Linear(in_features=219, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.1554911608578311, inplace=False)\n  )\n)\nn_comp 104\n[CV 1/5] END activation=1, batch=40, eta=0.00015512259126484746, lin_layer_dropouts=[0.1554911608578311, 0.1554911608578311, 0.1554911608578311, 0.1554911608578311, 0.1554911608578311], lin_layer_sizes=[219], loss=2, max_epochs=181, n_comp=104;, score=0.531 total time=  10.4s\nFITTING\nn_comp 5\nshape (1040, 5)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=5, out_features=178, bias=True)\n    (1): Linear(in_features=178, out_features=178, bias=True)\n  )\n  (outpout_layer): Linear(in_features=178, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-1): 2 x Dropout(p=0.19146343737689492, inplace=False)\n  )\n)\nn_comp 5\n[CV 4/5] END activation=1, batch=34, eta=0.004827588872094672, lin_layer_dropouts=[0.19146343737689492, 0.19146343737689492, 0.19146343737689492, 0.19146343737689492, 0.19146343737689492], lin_layer_sizes=[178, 178], loss=2, max_epochs=266, n_comp=5;, score=0.804 total time=  22.6s\nFITTING\nn_comp 4\nshape (1040, 4)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=4, out_features=244, bias=True)\n    (1-3): 3 x Linear(in_features=244, out_features=244, bias=True)\n  )\n  (outpout_layer): Linear(in_features=244, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.4478817978367597, inplace=False)\n  )\n)\nn_comp 4\n[CV 5/5] END activation=3, batch=20, eta=0.0004028632082859626, lin_layer_dropouts=[0.4478817978367597, 0.4478817978367597, 0.4478817978367597, 0.4478817978367597, 0.4478817978367597], lin_layer_sizes=[244, 244, 244, 244], loss=0, max_epochs=105, n_comp=4;, score=0.623 total time=  26.6s\nFITTING\nn_comp 3\nshape (1040, 3)\nmodel FeedForwardNN(\n  (activation): Tanh()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=3, out_features=124, bias=True)\n    (1-3): 3 x Linear(in_features=124, out_features=124, bias=True)\n  )\n  (outpout_layer): Linear(in_features=124, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.32384506027068116, inplace=False)\n  )\n)\nn_comp 3\n[CV 5/5] END activation=2, batch=40, eta=0.0006552344878295669, lin_layer_dropouts=[0.32384506027068116, 0.32384506027068116, 0.32384506027068116, 0.32384506027068116, 0.32384506027068116], lin_layer_sizes=[124, 124, 124, 124], loss=0, max_epochs=242, n_comp=3;, score=0.662 total time=  25.5s\nFITTING\nn_comp 19\nshape (1040, 19)\nmodel FITTING\nn_comp 76\nshape (1040, 76)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=76, out_features=195, bias=True)\n    (1-3): 3 x Linear(in_features=195, out_features=195, bias=True)\n  )\n  (outpout_layer): Linear(in_features=195, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.10616955533913808, inplace=False)\n  )\n)\nn_comp 76\n[CV 2/5] END activation=1, batch=31, eta=0.031428808908401086, lin_layer_dropouts=[0.10616955533913808, 0.10616955533913808, 0.10616955533913808, 0.10616955533913808, 0.10616955533913808], lin_layer_sizes=[195, 195, 195, 195], loss=0, max_epochs=170, n_comp=76;, score=0.000 total time=  22.8s\nFITTING\nn_comp 64\nshape (1040, 64)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=64, out_features=193, bias=True)\n    (1-2): 2 x Linear(in_features=193, out_features=193, bias=True)\n  )\n  (outpout_layer): Linear(in_features=193, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.0453032172664104, inplace=False)\n  )\n)\nn_comp 64\n[CV 1/5] END activation=3, batch=23, eta=0.0004992453416923981, lin_layer_dropouts=[0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104], lin_layer_sizes=[193, 193, 193], loss=2, max_epochs=253, n_comp=64;, score=0.981 total time=  43.0s\nFITTING\nn_comp 54\nshape (1040, 54)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=54, out_features=167, bias=True)\n    (1): Linear(in_features=167, out_features=167, bias=True)\n  )\n  (outpout_layer): Linear(in_features=167, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-1): 2 x Dropout(p=0.45466020103939103, inplace=False)\n  )\n)\nn_comp 54\n[CV 1/5] END activation=3, batch=15, eta=0.00012681352169084594, lin_layer_dropouts=[0.45466020103939103, 0.45466020103939103, 0.45466020103939103, 0.45466020103939103, 0.45466020103939103], lin_layer_sizes=[167, 167], loss=1, max_epochs=399, n_comp=54;, score=0.958 total time= 1.2min\nFITTING\nn_comp 40\nshape (1040, 40)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=40, out_features=209, bias=True)\n    (1-2): 2 x Linear(in_features=209, out_features=209, bias=True)\n  )\n  (outpout_layer): Linear(in_features=209, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.1632703844029177, inplace=False)\n  )\n)\nn_comp 40\n[CV 3/5] END activation=3, batch=21, eta=0.015199034037054074, lin_layer_dropouts=[0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177], lin_layer_sizes=[209, 209, 209], loss=0, max_epochs=199, n_comp=40;, score=0.881 total time=  39.4s\nFITTING\nn_comp 104\nshape (1040, 104)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=104, out_features=219, bias=True)\n  )\n  (outpout_layer): Linear(in_features=219, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.1554911608578311, inplace=False)\n  )\n)\nn_comp 104\n[CV 2/5] END activation=1, batch=40, eta=0.00015512259126484746, lin_layer_dropouts=[0.1554911608578311, 0.1554911608578311, 0.1554911608578311, 0.1554911608578311, 0.1554911608578311], lin_layer_sizes=[219], loss=2, max_epochs=181, n_comp=104;, score=0.485 total time=  10.4s\nFITTING\nn_comp 42\nshape (1040, 42)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=42, out_features=140, bias=True)\n    (1-2): 2 x Linear(in_features=140, out_features=140, bias=True)\n  )\n  (outpout_layer): Linear(in_features=140, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.24689779818219537, inplace=False)\n  )\n)\nn_comp 42\n[CV 2/5] END activation=1, batch=62, eta=0.020554245520150744, lin_layer_dropouts=[0.24689779818219537, 0.24689779818219537, 0.24689779818219537, 0.24689779818219537, 0.24689779818219537], lin_layer_sizes=[140, 140, 140], loss=2, max_epochs=355, n_comp=42;, score=0.827 total time=  24.2s\nFITTING\nn_comp 71\nshape (1040, 71)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=71, out_features=174, bias=True)\n  )\n  (outpout_layer): Linear(in_features=174, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.20519146151781487, inplace=False)\n  )\n)\nn_comp 71\n[CV 2/5] END activation=1, batch=44, eta=0.000559598687800608, lin_layer_dropouts=[0.20519146151781487, 0.20519146151781487, 0.20519146151781487, 0.20519146151781487, 0.20519146151781487], lin_layer_sizes=[174], loss=0, max_epochs=169, n_comp=71;, score=0.673 total time=   8.7s\nFITTING\nn_comp 28\nshape (1040, 28)\nmodel FeedForwardNN(\n  (activation): Tanh()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=28, out_features=48, bias=True)\n    (1): Linear(in_features=48, out_features=48, bias=True)\n  )\n  (outpout_layer): Linear(in_features=48, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-1): 2 x Dropout(p=0.46484882617128653, inplace=False)\n  )\n)\nn_comp 28\n[CV 3/5] END activation=2, batch=58, eta=0.0003045536871539678, lin_layer_dropouts=[0.46484882617128653, 0.46484882617128653, 0.46484882617128653, 0.46484882617128653, 0.46484882617128653], lin_layer_sizes=[48, 48], loss=0, max_epochs=143, n_comp=28;, score=0.492 total time=   6.7s\nFITTING\nn_comp 89\nshape (1040, 89)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=89, out_features=78, bias=True)\n    (1-3): 3 x Linear(in_features=78, out_features=78, bias=True)\n  )\n  (outpout_layer): Linear(in_features=78, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.4462794992449889, inplace=False)\n  )\n)\nn_comp 89\n[CV 4/5] END activation=3, batch=51, eta=0.0003628358380354917, lin_layer_dropouts=[0.4462794992449889, 0.4462794992449889, 0.4462794992449889, 0.4462794992449889, 0.4462794992449889], lin_layer_sizes=[78, 78, 78, 78], loss=1, max_epochs=357, n_comp=89;, score=0.919 total time=  28.3s\nFITTING\nn_comp 56\nshape (1040, 56)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=56, out_features=134, bias=True)\n  )\n  (outpout_layer): Linear(in_features=134, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.3481521364198942, inplace=False)\n  )\n)\nn_comp 56\n[CV 1/5] END activation=1, batch=59, eta=0.0005503363365456094, lin_layer_dropouts=[0.3481521364198942, 0.3481521364198942, 0.3481521364198942, 0.3481521364198942, 0.3481521364198942], lin_layer_sizes=[134], loss=0, max_epochs=122, n_comp=56;, score=0.558 total time=   5.0s\nFITTING\nn_comp 56\nshape (1040, 56)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=56, out_features=134, bias=True)\n  )\n  (outpout_layer): Linear(in_features=134, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.3481521364198942, inplace=False)\n  )\n)\nn_comp 56\n[CV 5/5] END activation=1, batch=59, eta=0.0005503363365456094, lin_layer_dropouts=[0.3481521364198942, 0.3481521364198942, 0.3481521364198942, 0.3481521364198942, 0.3481521364198942], lin_layer_sizes=[134], loss=0, max_epochs=122, n_comp=56;, score=0.512 total time=   4.9s\nFITTING\nn_comp 19\nshape (1040, 19)\nmodel FeedForwardNN(\n  (activation): ReLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=19, out_features=90, bias=True)\n  )\n  (outpout_layer): Linear(in_features=90, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.20551850665911564, inplace=False)\n  )\n)\nn_comp 19\n[CV 5/5] END activation=0, batch=56, eta=0.08508340610643304, lin_layer_dropouts=[0.20551850665911564, 0.20551850665911564, 0.20551850665911564, 0.20551850665911564, 0.20551850665911564], lin_layer_sizes=[90], loss=0, max_epochs=394, n_comp=19;, score=0.808 total time=  16.0s\nFITTING\nn_comp 20\nshape (1040, 20)\nmodel FITTING\nn_comp 64\nshape (1300, 64)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=64, out_features=193, bias=True)\n    (1-2): 2 x Linear(in_features=193, out_features=193, bias=True)\n  )\n  (outpout_layer): Linear(in_features=193, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.0453032172664104, inplace=False)\n  )\n)\nBest score: 0.962308 using {'activation': 3, 'batch': 23, 'eta': 0.0004992453416923981, 'lin_layer_dropouts': [0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104], 'lin_layer_sizes': [193, 193, 193], 'loss': 2, 'max_epochs': 253, 'n_comp': 64}\n"
        }
      ],
      "execution_count": 44,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T17:12:50.791447Z",
          "iopub.execute_input": "2024-12-18T17:12:50.791927Z"
        },
        "gather": {
          "logged": 1734624154767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# def plot_search_results(grid):\n",
        "#     \"\"\"\n",
        "#     Params: \n",
        "#         grid: A trained GridSearchCV object.\n",
        "#     \"\"\"\n",
        "#     ## Results from grid search\n",
        "#     results = grid.cv_results_\n",
        "#     means_test = results['mean_test_score']\n",
        "#     stds_test = results['std_test_score']\n",
        "#     #means_train = results['mean_train_score']\n",
        "#     #stds_train = results['std_train_score']\n",
        "\n",
        "#     ## Getting indexes of values per hyper-parameter\n",
        "#     masks=[]\n",
        "#     masks_names= list(grid.best_params_.keys())\n",
        "#     for p_k, p_v in grid.best_params_.items():\n",
        "#         masks.append(list(results['param_'+p_k].data==p_v))\n",
        "\n",
        "#     params=grid.param_grid\n",
        "\n",
        "#     ## Ploting results\n",
        "#     fig, ax = plt.subplots(1,len(params),sharex='none', sharey='all',figsize=(20,5))\n",
        "#     fig.suptitle('Score per parameter')\n",
        "#     fig.text(0.04, 0.5, 'MEAN SCORE', va='center', rotation='vertical')\n",
        "#     pram_preformace_in_best = {}\n",
        "#     for i, p in enumerate(masks_names):\n",
        "#         m = np.stack(masks[:i] + masks[i+1:])\n",
        "#         pram_preformace_in_best\n",
        "#         best_parms_mask = m.all(axis=0)\n",
        "#         best_index = np.where(best_parms_mask)[0]\n",
        "#         x = np.array(params[p])\n",
        "#         y_1 = np.array(means_test[best_index])\n",
        "#         e_1 = np.array(stds_test[best_index])\n",
        "#         #y_2 = np.array(means_train[best_index])\n",
        "#         #e_2 = np.array(stds_train[best_index])\n",
        "#         ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
        "#         #ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
        "#         ax[i].set_xlabel(p.upper())\n",
        "\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "FITTING\nn_comp 76\nshape (1040, 76)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=76, out_features=195, bias=True)\n    (1-3): 3 x Linear(in_features=195, out_features=195, bias=True)\n  )\n  (outpout_layer): Linear(in_features=195, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.10616955533913808, inplace=False)\n  )\n)\nn_comp 76\n[CV 1/5] END activation=1, batch=31, eta=0.031428808908401086, lin_layer_dropouts=[0.10616955533913808, 0.10616955533913808, 0.10616955533913808, 0.10616955533913808, 0.10616955533913808], lin_layer_sizes=[195, 195, 195, 195], loss=0, max_epochs=170, n_comp=76;, score=0.012 total time=  31.6s\nFITTING\nn_comp 64\nshape (1040, 64)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=64, out_features=193, bias=True)\n    (1-2): 2 x Linear(in_features=193, out_features=193, bias=True)\n  )\n  (outpout_layer): Linear(in_features=193, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.0453032172664104, inplace=False)\n  )\n)\nn_comp 64\n[CV 3/5] END activation=3, batch=23, eta=0.0004992453416923981, lin_layer_dropouts=[0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104], lin_layer_sizes=[193, 193, 193], loss=2, max_epochs=253, n_comp=64;, score=0.958 total time=  35.8s\nFITTING\nn_comp 54\nshape (1040, 54)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=54, out_features=167, bias=True)\n    (1): Linear(in_features=167, out_features=167, bias=True)\n  )\n  (outpout_layer): Linear(in_features=167, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-1): 2 x Dropout(p=0.45466020103939103, inplace=False)\n  )\n)\nn_comp 54\n[CV 2/5] END activation=3, batch=15, eta=0.00012681352169084594, lin_layer_dropouts=[0.45466020103939103, 0.45466020103939103, 0.45466020103939103, 0.45466020103939103, 0.45466020103939103], lin_layer_sizes=[167, 167], loss=1, max_epochs=399, n_comp=54;, score=0.938 total time=  43.3s\nFITTING\nn_comp 40\nshape (1040, 40)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=40, out_features=209, bias=True)\n    (1-2): 2 x Linear(in_features=209, out_features=209, bias=True)\n  )\n  (outpout_layer): Linear(in_features=209, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.1632703844029177, inplace=False)\n  )\n)\nn_comp 40\n[CV 1/5] END activation=3, batch=21, eta=0.015199034037054074, lin_layer_dropouts=[0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177], lin_layer_sizes=[209, 209, 209], loss=0, max_epochs=199, n_comp=40;, score=0.908 total time=  22.7s\nFITTING\nn_comp 40\nshape (1040, 40)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=40, out_features=209, bias=True)\n    (1-2): 2 x Linear(in_features=209, out_features=209, bias=True)\n  )\n  (outpout_layer): Linear(in_features=209, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-2): 3 x Dropout(p=0.1632703844029177, inplace=False)\n  )\n)\nn_comp 40\n[CV 2/5] END activation=3, batch=21, eta=0.015199034037054074, lin_layer_dropouts=[0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177, 0.1632703844029177], lin_layer_sizes=[209, 209, 209], loss=0, max_epochs=199, n_comp=40;, score=0.862 total time=  30.9s\nFITTING\nn_comp 33\nshape (1040, 33)\nmodel FeedForwardNN(\n  (activation): ReLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=33, out_features=246, bias=True)\n  )\n  (outpout_layer): Linear(in_features=246, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.007039911357542228, inplace=False)\n  )\n)\nn_comp 33\n[CV 2/5] END activation=0, batch=51, eta=0.0007593893885357789, lin_layer_dropouts=[0.007039911357542228, 0.007039911357542228, 0.007039911357542228, 0.007039911357542228, 0.007039911357542228], lin_layer_sizes=[246], loss=2, max_epochs=428, n_comp=33;, score=0.958 total time=  19.4s\nFITTING\nn_comp 5\nshape (1040, 5)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=5, out_features=178, bias=True)\n    (1): Linear(in_features=178, out_features=178, bias=True)\n  )\n  (outpout_layer): Linear(in_features=178, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-1): 2 x Dropout(p=0.19146343737689492, inplace=False)\n  )\n)\nn_comp 5\n[CV 3/5] END activation=1, batch=34, eta=0.004827588872094672, lin_layer_dropouts=[0.19146343737689492, 0.19146343737689492, 0.19146343737689492, 0.19146343737689492, 0.19146343737689492], lin_layer_sizes=[178, 178], loss=2, max_epochs=266, n_comp=5;, score=0.788 total time=  22.3s\nFITTING\nn_comp 4\nshape (1040, 4)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=4, out_features=244, bias=True)\n    (1-3): 3 x Linear(in_features=244, out_features=244, bias=True)\n  )\n  (outpout_layer): Linear(in_features=244, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.4478817978367597, inplace=False)\n  )\n)\nn_comp 4\n[CV 4/5] END activation=3, batch=20, eta=0.0004028632082859626, lin_layer_dropouts=[0.4478817978367597, 0.4478817978367597, 0.4478817978367597, 0.4478817978367597, 0.4478817978367597], lin_layer_sizes=[244, 244, 244, 244], loss=0, max_epochs=105, n_comp=4;, score=0.704 total time=  25.6s\nFITTING\nn_comp 3\nshape (1040, 3)\nmodel FeedForwardNN(\n  (activation): Tanh()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=3, out_features=124, bias=True)\n    (1-3): 3 x Linear(in_features=124, out_features=124, bias=True)\n  )\n  (outpout_layer): Linear(in_features=124, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.32384506027068116, inplace=False)\n  )\n)\nn_comp 3\n[CV 2/5] END activation=2, batch=40, eta=0.0006552344878295669, lin_layer_dropouts=[0.32384506027068116, 0.32384506027068116, 0.32384506027068116, 0.32384506027068116, 0.32384506027068116], lin_layer_sizes=[124, 124, 124, 124], loss=0, max_epochs=242, n_comp=3;, score=0.735 total time=  20.9s\nFITTING\nn_comp 113\nshape (1040, 113)\nmodel FeedForwardNN(\n  (activation): LeakyReLU(negative_slope=0.01)\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=113, out_features=219, bias=True)\n  )\n  (outpout_layer): Linear(in_features=219, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0): Dropout(p=0.10938210978653512, inplace=False)\n  )\n)\nn_comp 113\n[CV 3/5] END activation=3, batch=22, eta=0.00031979607306038295, lin_layer_dropouts=[0.10938210978653512, 0.10938210978653512, 0.10938210978653512, 0.10938210978653512, 0.10938210978653512], lin_layer_sizes=[219], loss=0, max_epochs=327, n_comp=113;, score=0.923 total time=  18.1s\nFITTING\nn_comp 55\nshape (1040, 55)\nmodel FeedForwardNN(\n  (activation): SiLU()\n  (lin_layers): ModuleList(\n    (0): Linear(in_features=55, out_features=201, bias=True)\n    (1-3): 3 x Linear(in_features=201, out_features=201, bias=True)\n  )\n  (outpout_layer): Linear(in_features=201, out_features=1, bias=True)\n  (dropout_layers): ModuleList(\n    (0-3): 4 x Dropout(p=0.22389158228654582, inplace=False)\n  )\n)\nn_comp 55\n[CV 1/5] END activation=1, batch=9, eta=0.003915648958243001, lin_layer_dropouts=[0.22389158228654582, 0.22389158228654582, 0.22389158228654582, 0.22389158228654582, 0.22389158228654582], lin_layer_sizes=[201, 201, 201, 201], loss=2, max_epochs=333, n_comp=55;, score=0.950 total time= 1.5min\n"
        }
      ],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734624408280
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_search_results(random_search)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'bool' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_search_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_search\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[53], line 18\u001b[0m, in \u001b[0;36mplot_search_results\u001b[0;34m(grid)\u001b[0m\n\u001b[1;32m     16\u001b[0m masks_names\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p_k, p_v \u001b[38;5;129;01min\u001b[39;00m grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 18\u001b[0m     masks\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mp_k\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mp_v\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m params\u001b[38;5;241m=\u001b[39mgrid\u001b[38;5;241m.\u001b[39mparam_grid\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m## Ploting results\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
          ]
        }
      ],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734624409666
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_search.best_params_.items()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "dict_items([('activation', 3), ('batch', 23), ('eta', 0.0004992453416923981), ('lin_layer_dropouts', [0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104, 0.0453032172664104]), ('lin_layer_sizes', [193, 193, 193]), ('loss', 2), ('max_epochs', 253), ('n_comp', 64)])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734624536088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nnreg = NeuralNetRegressor(input_size=input_size, random_state=55, **random_grid_result.best_params_)\n",
        "# nnreg.fit(X_train, y_train,do_print=True, X_valid=X_valid, y_valid=y_valid )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734602258371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nnreg.model.eval()\n",
        "# y_pred = nnreg.model(torch.tensor(X_valid).float())\n",
        "\n",
        "# #np.mean(np.square(y_valid-y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734607413583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred2 = nnreg.predict(X_valid)\n",
        "# y_pred2 - y_pred.detach().numpy()[:,0]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734607415574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss = nn.MSELoss()\n",
        "# loss(torch.tensor(y_valid),torch.tensor(y_pred))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734602853061
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y_pred = nouveau_model.predict(X_valid)\n",
        "y_pred_train = nouveau_model.predict(X_train)\n",
        "predictions = nouveau_model.predict(X_test)*100\n",
        "\n",
        "# Vérifiez les sorties du modèle\n",
        "print(\"y_pred contains NaN:\", np.isnan(predictions).any())\n",
        "\n",
        "\n",
        "\n",
        "# Calculer le t_score\n",
        "train_score = np.mean(np.abs(y_pred_train-y_train)*100<=5)\n",
        "print(\"t_score train :\", train_score)\n",
        "\n",
        "ids = np.arange(1, len(predictions) + 1)\n",
        "\n",
        "# Create a DataFrame for the output\n",
        "output_df = pd.DataFrame({\n",
        "\n",
        "    'ID': ids,\n",
        "\n",
        "    'PURITY': predictions[:,0]\n",
        "\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_df.to_csv('predictions.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "n_comp 64\nn_comp 64\ny_pred contains NaN: False\nt_score train : 1.0\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-18T17:10:15.282542Z",
          "iopub.execute_input": "2024-12-18T17:10:15.282963Z",
          "iopub.status.idle": "2024-12-18T17:10:15.307765Z",
          "shell.execute_reply.started": "2024-12-18T17:10:15.282927Z",
          "shell.execute_reply": "2024-12-18T17:10:15.306565Z"
        },
        "gather": {
          "logged": 1734624902458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": "array([[0.5839623 ],\n       [0.17583114],\n       [0.18533981],\n       ...,\n       [0.516559  ],\n       [0.15392096],\n       [0.19709522]], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734624921508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": "array([[0.585     ],\n       [0.186     ],\n       [0.19881719],\n       ...,\n       [0.534     ],\n       [0.136     ],\n       [0.196     ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1734624928448
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10229122,
          "sourceType": "datasetVersion",
          "datasetId": 6324471
        },
        {
          "sourceId": 10229125,
          "sourceType": "datasetVersion",
          "datasetId": 6324474
        }
      ],
      "dockerImageVersionId": 30804,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}