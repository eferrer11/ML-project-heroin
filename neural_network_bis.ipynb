{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from skorch.callbacks import EpochScoring\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "spectrum = data.iloc[:, 6:]\n",
    "\n",
    "#spectrum_filtered = pd.DataFrame(savgol_filter(spectrum, 7, 3, deriv = 2, axis = 0))\n",
    "#spectrum_filtered_st = zscore(spectrum_filtered, axis = 1)\n",
    "\n",
    "X = spectrum\n",
    "y = data[\"PURITY\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "X_train_standardized = standardizer.fit_transform(X_train)\n",
    "X_valid_standardized = standardizer.transform(X_valid)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train_standardized, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_valid_tensor = torch.tensor(X_valid_standardized, dtype=torch.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train_tensor.shape[1], 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    " \n",
    "# loss function and optimizer\n",
    "loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got Sequential(\n  (0): Linear(in_features=125, out_features=100, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=100, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=1, bias=True)\n  (5): Sigmoid()\n) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.005\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m25\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule__fc1_out_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m128\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule__fc2_out_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m],\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m nouveau_model \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest MSE: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (grid_result\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/base.py:1466\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1462\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1463\u001b[0m )\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1466\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[1;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MLCourse/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'estimator' parameter of GridSearchCV must be an object implementing 'fit'. Got Sequential(\n  (0): Linear(in_features=125, out_features=100, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=100, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=1, bias=True)\n  (5): Sigmoid()\n) instead."
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'eta': [0.001, 0.005, 0.01],\n",
    "    'max_epochs': [20,25],\n",
    "    'module__fc1_out_features': [100, 128],\n",
    "    'module__fc2_out_features': [64, 128],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, params, refit=True, cv=5, scoring='neg_mean_squared_error',verbose=0)\n",
    "grid_result = grid_search.fit(X_train_tensor, y_train_tensor)\n",
    "nouveau_model = grid_result.best_estimator_\n",
    "\n",
    "print(\"Best MSE: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(grid_result.best_params_[\"eta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = grid_result.best_params_[\"max_epochs\"]    # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "batches_per_epoch = len(X_train_tensor) // batch_size\n",
    "train_loss = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(batches_per_epoch):\n",
    "        start = i * batch_size\n",
    "        # take a batch\n",
    "        Xbatch = X_train_tensor[start:start+batch_size]\n",
    "        ybatch = X_train_tensor[start:start+batch_size]\n",
    "        # forward pass\n",
    "        y_pred = model(Xbatch)\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        # store metrics\n",
    "        train_loss.append(float(loss))\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate trained model with test set\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "# Calculer la MSE\n",
    "mse = np.mean((y_pred - y_valid_tensor.numpy())**2)\n",
    "print(\"MSE :\", mse)\n",
    "\n",
    "# Calculer le t_score\n",
    "predictions_tensor = torch.tensor(y_pred, dtype=torch.float32)\n",
    "t_score = torch.mean((torch.abs(predictions_tensor - y_valid_tensor) <= 5).float())\n",
    "print(\"t_score :\", t_score.item())\n",
    "\n",
    "# Afficher la courbe d'apprentissage\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Learning Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
