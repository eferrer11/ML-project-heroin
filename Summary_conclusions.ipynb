{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project was to find the best model to predict the purity of heroin using the data from differents samples.\n",
    "\n",
    "### Insights from exploration\n",
    "\n",
    "First, we observed the data to better understand the features i.e. observe the correlation they had between each other, the \"importance\" they had to predict the purity correctly.\n",
    "\n",
    "We try to create new features from the pure substances furnished in substances.csv by making a dot product between the original data and the pure heroin. It gave us 1432 features in total that we used in the linear model.\n",
    "\n",
    "# *A COMPLETER*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the preprocessing of both linear and non linear model we removed the first 6 columns of the dataset which were text. We chose a split with a rate of 0.2 for the validation set.\n",
    "\n",
    "- We try to use the new features we created with the pure substances and thus perform PCA to reduce the number of features and find out that only --- were necessary to explained the variance. We also perform PCA on the original data set and only --- were necessary to explained the variance.\n",
    "\n",
    "- We also we perform a standardization (only for the Neural Network). Then, we tried to make an OneHot encoding but the result was not convincing since the score diminished.\n",
    "\n",
    "# *A COMPLETER*\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *New features PCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(data.iloc[:, 6:])\n",
    "\n",
    "# Calculate the cumulative explained variance\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components needed to explain 95% of the variance: {n_components}\")\n",
    "\n",
    "plt.plot(np.arange(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Original features PCA*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(data.iloc[:, 6:])\n",
    "\n",
    "# Calculate the cumulative explained variance\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "print(f\"Number of principal components needed to explain 95% of the variance: {n_components}\")\n",
    "\n",
    "plt.plot(np.arange(1, len(explained_variance) + 1), explained_variance, marker='o')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Explained Variance')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA - Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning, we tried to implement a polynomial method but the results were not as good as we expected thus we try to make a ridge regression method. We try both new and original features and the new features showed a best score.\n",
    "\n",
    "We perform a GridSearch to find the best hyperparameters (WHICH ONE ?) and notably the lambda parameter. We plotted the lambda compared to the RMSE to find the best interval in the GridSearch.\n",
    "\n",
    "# *A COMPLETER*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(np.logspace(-7, 0, 100), np.sqrt(-grid_search.cv_results_['mean_test_score']))\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mach1.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final score showed a small underfitting: \n",
    "- **train : 0.6307692307692307**\n",
    "\n",
    "- **test : 0.7025641025641025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a RandomizedSearch to find the best hyperparameters i.e. learning rate, the max number of epochs, the size of batches, the number of hidden layers and their sizes, the dropout for each layer and the activation function (ReLU, SiLU, Tanh or LeakyReLU). We perform a gradient descent with Adam optimizer and we used a weight decay of 1e-4. We also tried SGD optimizer but finally choose to kept the former one. For the loss we try several one for example L1, Huber we try to create our loss but the score were not as good as the MSE thus we kept it to evaluate the training. We also tried to use the new features we created from the dot product but the result was not satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PLOT OF LOSS NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Ã  ajouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two best scores we obtained were:\n",
    "- **train :**\n",
    "\n",
    "- **test :**\n",
    "\n",
    "The hyperparameters were: \n",
    "\n",
    "- **train :**\n",
    "\n",
    "- **test :**\n",
    "\n",
    "The hyperparameters were:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
